name: "china_lenet"
input: "data"
input_dim: 1
input_dim: 3
input_dim: 20
input_dim: 14

layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
  }
}

layer{
        name: "relu1"
        type: "ReLU"
        bottom: "conv1"
        top: "conv1"
}

layer {
      name: "conv2"
      type: "Convolution"
      bottom: "conv1"
      top: "conv2"
      param {
            lr_mult: 1
      }
      param {
            lr_mult: 2
      }
      convolution_param{
        num_output: 32
        kernel_size: 3
        stride: 1
      }
}

layer{
        name: "relu2"
        type: "ReLU"
        bottom: "conv2"
        top: "conv2"
}

layer{
        name: "batch_norm1"
        type: "BatchNorm"
        bottom: "conv2"
        top: "batch_norm1"
}

layer {
  name: "pool1"
  type: "Pooling"
  bottom: "batch_norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}

layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 1
    }
}

layer{
        name: "relu3"
        type: "ReLU"
        bottom: "conv3"
        top: "conv3"
}

layer {
      name: "conv4"
      type: "Convolution"
      bottom: "conv3"
      top: "conv4"
      param {
            lr_mult: 1
            }
      param {
            lr_mult:2
            }
      convolution_param {
                         num_output: 64
                         kernel_size: 3
                         stride: 1
    			 }

}

layer{
        name: "relu4"
        type: "ReLU"
        bottom: "conv4"
        top: "conv4"
}


layer {
      name: "batch_norm2"
      type: "BatchNorm"
      bottom: "conv4"
      top: "batch_norm2"
}

layer {
      name: "gap"
      type: "Pooling"
      bottom: "batch_norm2"
      top: "gap"
      pooling_param {
                    pool: AVE
                    global_pooling: true
      }
}

layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "gap"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
 
  }
}

layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}

layer {
      name: "dropout"
      type: "Dropout"
      bottom: "ip1"
      top: "ip1"
      dropout_param: {
                     dropout_ratio: 0.5
      }
}

layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
		       num_output: 36
      		       }	
}

layer{
	name: "prob"
	type: "Softmax"
	bottom: "ip2"
	top: "prob"
}